{
  "best_metric": 2.8833560943603516,
  "best_model_checkpoint": "results/llm_results/flan_t5_base_fine_tuning_results_v1/checkpoint-165",
  "epoch": 14.926315789473684,
  "eval_steps": 500,
  "global_step": 165,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08421052631578947,
      "grad_norm": 8.397521018981934,
      "learning_rate": 5.000000000000001e-07,
      "loss": 10.3146,
      "step": 1
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 5.058825492858887,
      "learning_rate": 2.5e-06,
      "loss": 9.4511,
      "step": 5
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 7.26391077041626,
      "learning_rate": 5e-06,
      "loss": 8.0914,
      "step": 10
    },
    {
      "epoch": 0.9263157894736842,
      "eval_loss": 12.685966491699219,
      "eval_runtime": 3.2096,
      "eval_samples_per_second": 14.955,
      "eval_steps_per_second": 7.478,
      "step": 11
    },
    {
      "epoch": 1.3368421052631578,
      "grad_norm": 6.7841057777404785,
      "learning_rate": 7.5e-06,
      "loss": 10.7629,
      "step": 15
    },
    {
      "epoch": 1.7578947368421054,
      "grad_norm": 3.558745861053467,
      "learning_rate": 1e-05,
      "loss": 9.6503,
      "step": 20
    },
    {
      "epoch": 1.9263157894736842,
      "eval_loss": 12.395397186279297,
      "eval_runtime": 3.2404,
      "eval_samples_per_second": 14.813,
      "eval_steps_per_second": 7.407,
      "step": 22
    },
    {
      "epoch": 2.2526315789473683,
      "grad_norm": 7.384421348571777,
      "learning_rate": 1.25e-05,
      "loss": 10.4539,
      "step": 25
    },
    {
      "epoch": 2.6736842105263157,
      "grad_norm": 7.83282995223999,
      "learning_rate": 1.5e-05,
      "loss": 8.1681,
      "step": 30
    },
    {
      "epoch": 2.9263157894736844,
      "eval_loss": 11.833109855651855,
      "eval_runtime": 3.3062,
      "eval_samples_per_second": 14.518,
      "eval_steps_per_second": 7.259,
      "step": 33
    },
    {
      "epoch": 3.168421052631579,
      "grad_norm": 7.147950172424316,
      "learning_rate": 1.75e-05,
      "loss": 10.9046,
      "step": 35
    },
    {
      "epoch": 3.5894736842105264,
      "grad_norm": 4.1860246658325195,
      "learning_rate": 2e-05,
      "loss": 8.3122,
      "step": 40
    },
    {
      "epoch": 3.9263157894736844,
      "eval_loss": 10.901104927062988,
      "eval_runtime": 3.1344,
      "eval_samples_per_second": 15.314,
      "eval_steps_per_second": 7.657,
      "step": 44
    },
    {
      "epoch": 4.08421052631579,
      "grad_norm": 8.907713890075684,
      "learning_rate": 2.25e-05,
      "loss": 9.0514,
      "step": 45
    },
    {
      "epoch": 4.505263157894737,
      "grad_norm": 5.234803199768066,
      "learning_rate": 2.5e-05,
      "loss": 8.3666,
      "step": 50
    },
    {
      "epoch": 4.926315789473684,
      "grad_norm": 9.56242561340332,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 8.6364,
      "step": 55
    },
    {
      "epoch": 4.926315789473684,
      "eval_loss": 9.624207496643066,
      "eval_runtime": 3.2353,
      "eval_samples_per_second": 14.837,
      "eval_steps_per_second": 7.418,
      "step": 55
    },
    {
      "epoch": 5.421052631578947,
      "grad_norm": 5.424081325531006,
      "learning_rate": 3e-05,
      "loss": 7.9891,
      "step": 60
    },
    {
      "epoch": 5.842105263157895,
      "grad_norm": 13.223997116088867,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 8.3065,
      "step": 65
    },
    {
      "epoch": 5.926315789473684,
      "eval_loss": 8.358464241027832,
      "eval_runtime": 3.1419,
      "eval_samples_per_second": 15.278,
      "eval_steps_per_second": 7.639,
      "step": 66
    },
    {
      "epoch": 6.336842105263158,
      "grad_norm": 4.108814716339111,
      "learning_rate": 3.5e-05,
      "loss": 8.2016,
      "step": 70
    },
    {
      "epoch": 6.757894736842105,
      "grad_norm": 3.3777666091918945,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 6.5531,
      "step": 75
    },
    {
      "epoch": 6.926315789473684,
      "eval_loss": 7.406402587890625,
      "eval_runtime": 3.1294,
      "eval_samples_per_second": 15.339,
      "eval_steps_per_second": 7.669,
      "step": 77
    },
    {
      "epoch": 7.252631578947368,
      "grad_norm": 4.61146354675293,
      "learning_rate": 4e-05,
      "loss": 8.4818,
      "step": 80
    },
    {
      "epoch": 7.673684210526316,
      "grad_norm": 4.0555853843688965,
      "learning_rate": 4.25e-05,
      "loss": 6.8597,
      "step": 85
    },
    {
      "epoch": 7.926315789473684,
      "eval_loss": 6.566219329833984,
      "eval_runtime": 3.2293,
      "eval_samples_per_second": 14.864,
      "eval_steps_per_second": 7.432,
      "step": 88
    },
    {
      "epoch": 8.16842105263158,
      "grad_norm": 2.912224054336548,
      "learning_rate": 4.5e-05,
      "loss": 6.8446,
      "step": 90
    },
    {
      "epoch": 8.589473684210526,
      "grad_norm": 2.2266335487365723,
      "learning_rate": 4.75e-05,
      "loss": 4.9082,
      "step": 95
    },
    {
      "epoch": 8.926315789473684,
      "eval_loss": 5.752573490142822,
      "eval_runtime": 3.1363,
      "eval_samples_per_second": 15.305,
      "eval_steps_per_second": 7.652,
      "step": 99
    },
    {
      "epoch": 9.08421052631579,
      "grad_norm": 3.6656429767608643,
      "learning_rate": 5e-05,
      "loss": 6.7062,
      "step": 100
    },
    {
      "epoch": 9.505263157894737,
      "grad_norm": 2.642423391342163,
      "learning_rate": 4.791666666666667e-05,
      "loss": 5.1158,
      "step": 105
    },
    {
      "epoch": 9.926315789473684,
      "grad_norm": 1.7896666526794434,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 5.3169,
      "step": 110
    },
    {
      "epoch": 9.926315789473684,
      "eval_loss": 5.0172529220581055,
      "eval_runtime": 3.1272,
      "eval_samples_per_second": 15.349,
      "eval_steps_per_second": 7.675,
      "step": 110
    },
    {
      "epoch": 10.421052631578947,
      "grad_norm": 2.0737311840057373,
      "learning_rate": 4.375e-05,
      "loss": 5.4124,
      "step": 115
    },
    {
      "epoch": 10.842105263157894,
      "grad_norm": 2.103181838989258,
      "learning_rate": 4.166666666666667e-05,
      "loss": 4.4807,
      "step": 120
    },
    {
      "epoch": 10.926315789473684,
      "eval_loss": 4.425922870635986,
      "eval_runtime": 3.1367,
      "eval_samples_per_second": 15.303,
      "eval_steps_per_second": 7.651,
      "step": 121
    },
    {
      "epoch": 11.336842105263157,
      "grad_norm": 2.2963435649871826,
      "learning_rate": 3.958333333333333e-05,
      "loss": 5.22,
      "step": 125
    },
    {
      "epoch": 11.757894736842106,
      "grad_norm": 2.3006951808929443,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 4.2768,
      "step": 130
    },
    {
      "epoch": 11.926315789473684,
      "eval_loss": 3.946490526199341,
      "eval_runtime": 3.1168,
      "eval_samples_per_second": 15.4,
      "eval_steps_per_second": 7.7,
      "step": 132
    },
    {
      "epoch": 12.25263157894737,
      "grad_norm": 2.1445939540863037,
      "learning_rate": 3.541666666666667e-05,
      "loss": 4.5512,
      "step": 135
    },
    {
      "epoch": 12.673684210526316,
      "grad_norm": 2.674862861633301,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 3.9821,
      "step": 140
    },
    {
      "epoch": 12.926315789473684,
      "eval_loss": 3.545222520828247,
      "eval_runtime": 3.1431,
      "eval_samples_per_second": 15.271,
      "eval_steps_per_second": 7.636,
      "step": 143
    },
    {
      "epoch": 13.16842105263158,
      "grad_norm": 1.4849168062210083,
      "learning_rate": 3.125e-05,
      "loss": 3.7348,
      "step": 145
    },
    {
      "epoch": 13.589473684210526,
      "grad_norm": 3.2738521099090576,
      "learning_rate": 2.916666666666667e-05,
      "loss": 4.1049,
      "step": 150
    },
    {
      "epoch": 13.926315789473684,
      "eval_loss": 3.2050678730010986,
      "eval_runtime": 3.1349,
      "eval_samples_per_second": 15.312,
      "eval_steps_per_second": 7.656,
      "step": 154
    },
    {
      "epoch": 14.08421052631579,
      "grad_norm": 3.385016679763794,
      "learning_rate": 2.7083333333333332e-05,
      "loss": 3.3485,
      "step": 155
    },
    {
      "epoch": 14.505263157894737,
      "grad_norm": 1.9280822277069092,
      "learning_rate": 2.5e-05,
      "loss": 3.0707,
      "step": 160
    },
    {
      "epoch": 14.926315789473684,
      "grad_norm": 2.108441114425659,
      "learning_rate": 2.2916666666666667e-05,
      "loss": 2.9776,
      "step": 165
    },
    {
      "epoch": 14.926315789473684,
      "eval_loss": 2.8833560943603516,
      "eval_runtime": 3.1658,
      "eval_samples_per_second": 15.162,
      "eval_steps_per_second": 7.581,
      "step": 165
    }
  ],
  "logging_steps": 5,
  "max_steps": 220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 484670059315200.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
